{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JGR model Gillespie simulation in numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from scipy.integrate import trapz\n",
    "import numba\n",
    "import time \n",
    "\n",
    "    \n",
    "@numba.jit(nopython=True)\n",
    "def prop(n,m,params,gam,kap):\n",
    "    \"\"\"\n",
    "    Returns an array of propensities given a set of parameters\n",
    "    and an array of populations.\n",
    "    n -- population of moving grains\n",
    "    m -- population of stationary grains\n",
    "    params -- (nu,lam,sig,mu)\n",
    "    gam -- migration out \n",
    "    kap -- coupling between bed elevation and transport\n",
    "    \"\"\"\n",
    "    nu,lam,sig,mu = params\n",
    "    dm = kap*m\n",
    "    mp = 1+dm\n",
    "    if mp>2:\n",
    "        mp=2\n",
    "    mm = 1-dm\n",
    "    if mm<0:\n",
    "        mm=0\n",
    "    #out = np.array([nu,(lam+mu*n)*(1+dm), sig*n*(1-dm), gam*n])\n",
    "    out = np.array([nu,(lam+mu*n)*mp, sig*n*mm, gam*n])    \n",
    "    return out\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def sum_numba(ar):\n",
    "    \"\"\"sum numbers fast\"\"\"\n",
    "    return ar.sum()\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def sample(probs, probs_sum):\n",
    "    \"\"\"draw a random element from the discrete distribution probs/probs_sum\n",
    "    probs is an N-dimensional array and probs_sum = sum(probs)\"\"\"\n",
    "    q = np.random.rand() * probs_sum \n",
    "    i = 0\n",
    "    p_sum = 0.0\n",
    "    while p_sum < q:\n",
    "        p_sum += probs[i]\n",
    "        i += 1\n",
    "    return i - 1\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def sim(kap,params, tmax=1000): \n",
    "    \"\"\"\n",
    "    kap -- coupling between transport and bed elevation on 0<kap<1\n",
    "    params -- nu,lam,sig,mu (migration in, entrainment, deposition, collective entrainment)\n",
    "    tmax -- max time of the simulation in 1/[units of the rates] (i.e. seconds)\n",
    "    This function returns n,m,t \n",
    "    n -- sequence of # moving grains\n",
    "    m -- sequence of # stationary grains (relative to the mean)\n",
    "    t -- sequence of transition times\n",
    "    \"\"\"\n",
    "    nu, lam, sig, mu = params # all but gamma are specified\n",
    "    gam = nu/lam*(sig-mu) # computed by conservation of mass at z=0\n",
    "    #O = []\n",
    "    n = int((nu+lam)/(sig+gam-mu))\n",
    "    m = 0   \n",
    "    t = 0.0\n",
    "    N=[]\n",
    "    M=[]\n",
    "    T=[]\n",
    "    while t<tmax:\n",
    "        #T.append(t) # build up the output\n",
    "        #O.append((n,m,t))\n",
    "        N.append(n)\n",
    "        M.append(m)\n",
    "        T.append(t)\n",
    "        # select the transition\n",
    "        a = prop(n,m,params,gam,kap) # compute the propensities\n",
    "        a0 = sum_numba(a) # find the net propensity \n",
    "        t = t + (1/a0)*np.log(1/np.random.random()) # step the time\n",
    "        j=sample(a,a0) # index of the transition\n",
    "        # enact the transition\n",
    "        if j==1: # sorted by what I assume are most likely\n",
    "            n = n+1\n",
    "            m = m-1\n",
    "        elif j==2:\n",
    "            n = n-1\n",
    "            m = m+1\n",
    "        elif j==0:\n",
    "            n = n+1\n",
    "        else: # j==3\n",
    "            n = n-1\n",
    "    # shape the output\n",
    "    #n = np.array([s[0] for s in O])\n",
    "    #m = np.array([s[1] for s in O])\n",
    "    #t = np.array([s[2] for s in O])\n",
    "    #return n,m,t\n",
    "    return np.array(N),np.array(M),np.array(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perform all paper simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params_a = (5.45, 6.59, 4.67,3.74) # flow a\n",
    "params_g = (7.74,8.42,4.95,4.34)\n",
    "params_i = (15.56,22.07,4.52,3.56) # flow i \n",
    "params_l = (15.52,14.64,4.77,4.32)\n",
    "params_n = (15.45,24.49,3.64,4.24)\n",
    "params = [params_a, params_g, params_i, params_l, params_n]\n",
    "a = 0.3\n",
    "lvals = np.linspace(1,10,13)*a\n",
    "L = 22.5\n",
    "phi = 0.6\n",
    "z1 = np.pi*a**2/phi/L\n",
    "kaps = z1**2/(2*lvals)**2\n",
    "tmax = 100*3600\n",
    "i=-1\n",
    "j = len(kaps)*len(params)\n",
    "for p in params:\n",
    "    for kap in kaps:\n",
    "        i+=1\n",
    "        if i>51:\n",
    "            print(str(i) + ' of ' + str(j))\n",
    "            n,m,t = sim(kap,p,tmax=tmax)\n",
    "            np.save('sim-'+str(i),{'parameters':p,'kappa':kap,'n':n,'m':m,'t':t})\n",
    "            del n,m,t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def pdfer(q,dt,tm):\n",
    "    qvals = np.unique(q)\n",
    "    return np.array([qvals,[dt[q==qq].sum()/tm for qq in qvals]])\n",
    "@numba.jit(nopython=True)\n",
    "def binner(n,m,mvals,dt,o):\n",
    "    return np.array([(n[m==mm]**o*dt[m==mm]).sum()/dt[m==mm].sum() for mm in mvals])\n",
    "@numba.jit(nopython=True)\n",
    "def momenter(q,o,dt,tm):\n",
    "    return (q**o*dt).sum()/tm\n",
    "\n",
    "def analyze(i):\n",
    "    name='sim-'+str(i)+'.npy'\n",
    "    file=np.load(name,allow_pickle=True).item()\n",
    "    name=name[:-4]+'-ana'\n",
    "    n = file['n']\n",
    "    m = file['m']\n",
    "    t = file['t']\n",
    "    p = file['parameters']\n",
    "    kap = file['kappa']\n",
    "    del file\n",
    "    \n",
    "    # caluclate mean of n and variance of n \n",
    "    dt = np.diff(t)\n",
    "    tm = t[-1]\n",
    "    n = n[:-1]\n",
    "    #nbar = (n*dt).sum()/tm\n",
    "    nbar = momenter(n,1,dt,tm)\n",
    "    #nvar = (n**2*dt).sum()/tm-nbar**2\n",
    "    nvar = momenter(n,2,dt,tm)-nbar**2\n",
    "    del t \n",
    "    \n",
    "    # calculate mean of m and variance of m \n",
    "    m = m[:-1]\n",
    "    #mbar = (m*dt).sum()/tm\n",
    "    mbar = momenter(m,1,dt,tm)\n",
    "    #mvar = (m**2*dt).sum()/tm-mbar**2\n",
    "    mvar = momenter(m,2,dt,tm)-mbar**2\n",
    "    \n",
    "    # save all of these to output\n",
    "    out ={}\n",
    "    out['parameters']=p\n",
    "    out['kappa']=kap\n",
    "    out['mbar']=mbar\n",
    "    out['mvar']=mvar\n",
    "    out['nbar']=nbar\n",
    "    out['nvar']=nvar\n",
    "    \n",
    "    # now calculate the pdf of n and m\n",
    "    #nvals = np.unique(n)\n",
    "    #n_pdf = [dt[n==nn].sum()/tm for nn in nvals]\n",
    "    #n_pdf = np.array([nvals,n_pdf])\n",
    "    n_pdf = pdfer(n,dt,tm)\n",
    "    out['n_pdf']=n_pdf\n",
    "    del n_pdf\n",
    "    #del n_pdf,nvals\n",
    "\n",
    "    # and now the m pdf \n",
    "    #mvals = np.unique(m)\n",
    "    #m_pdf = [dt[m==mm].sum()/tm for mm in mvals]\n",
    "    #m_pdf = np.array([mvals,m_pdf])\n",
    "    m_pdf = pdfer(m,dt,tm)\n",
    "    out['m_pdf']=m_pdf\n",
    "    mvals = m_pdf[0]\n",
    "    del m_pdf\n",
    "\n",
    "    # now get the mean and variance of n held marginal to m\n",
    "    #n_bar_m = [(n[m==mm]*dt[m==mm]).sum()/dt[m==mm].sum() for mm in mvals]\n",
    "    n_bar_m = binner(n,m,mvals,dt,1)\n",
    "    out['n_bar_m']=np.array([mvals,n_bar_m])\n",
    "    #n_var_m = [(n[m==mm]**2*dt[m==mm]).sum()/dt[m==mm].sum() for mm in mvals]\n",
    "    n_var_m = binner(n,m,mvals,dt,2)-n_bar_m**2\n",
    "    #n_var_m = np.array(n_var_m) - np.array(n_bar_m)**2\n",
    "    out['n_var_m']=np.array([mvals,n_var_m])\n",
    "    del n_bar_m,n_var_m\n",
    "  \n",
    "    np.save(name,out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,52):\n",
    "    analyze(i)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now compute all resting time pdfs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rtcdf(i):\n",
    "    name='sim-'+str(i)+'.npy'\n",
    "    name1='sim-'+str(i)+'-ana.npy'\n",
    "    file=np.load(name,allow_pickle=True).item()\n",
    "    file1=np.load(name1,allow_pickle=True).item()\n",
    "    m,t = file['m'],file['t']\n",
    "    mv,pm = file1['m_pdf']\n",
    "    #del file, file1\n",
    "    #bins = np.linspace(1e-3,1e7,100)\n",
    "    bins = np.hstack((np.array([0]),np.geomspace(1e-7,1e7,num=150)))\n",
    "    \n",
    "    # generate masks of where entrainment and deposition events occur in the timeseries\n",
    "    erodemask = m[1:]-np.roll(m,1)[1:]==-1  # indices into t[1:] where erosion occurred \n",
    "    depositmask = m[1:]-np.roll(m,1)[1:]==1 # indices into t[1:] where deposition occurred \n",
    "    te = t[1:][erodemask]\n",
    "    td = t[1:][depositmask]\n",
    "    me = m[1:][erodemask]\n",
    "    md = m[1:][depositmask]\n",
    "    inputs = (te,me,td,md,mv,pm)\n",
    "    del mv,m,file,file1,name,name1,t,erodemask,depositmask\n",
    "    \n",
    "    def compute_crt(te, me, td, md, mv, bins = bins):\n",
    "        \"\"\"\n",
    "        compute conditional return time given\n",
    "        - entrainment timeseries te\n",
    "        - bed elevations me at entrainment\n",
    "        - deposition timeseries td\n",
    "        - bed elevations md at deposition\n",
    "        - a value mv at which to condition\n",
    "        - a set of bins in time over which to histogram\n",
    "        \"\"\"\n",
    "        returns = te[me==mv]\n",
    "        departs = td[md==mv+1]\n",
    "\n",
    "        if (len(returns)>1) and (len(departs)>1):\n",
    "            while (returns[0]<departs[0]):\n",
    "                returns=returns[1:]\n",
    "            while (departs[-1]>returns[-1]):\n",
    "                departs=departs[:-1]\n",
    "            k = len(departs)-len(returns)\n",
    "            if k>0:\n",
    "                departs = departs[k:]\n",
    "            elif k<0:\n",
    "                returns = returns[:k]\n",
    "        crt = returns - departs\n",
    "        H,_ = np.histogram(crt, bins=bins)\n",
    "        H = H.cumsum()\n",
    "        if H.max()>0:\n",
    "            H = 1.0-H/H.max()\n",
    "        return H\n",
    "\n",
    "    def compute_cdf(inputs, bins=bins):\n",
    "        te, me, td, md, m, pm = inputs # these come from loader\n",
    "        cdf = np.zeros(len(bins)-1,dtype=float) # sum into this iteratively\n",
    "        for mv,p in zip(m, pm): # iterate through all mvalues in question\n",
    "            c_cdf = compute_crt(te, me, td, md, mv)\n",
    "            cdf+=c_cdf*p\n",
    "        #data = np.array((bins[1:], cdf))\n",
    "        return bins[1:],cdf\n",
    "    bins, cdf = compute_cdf(inputs,bins=bins)\n",
    "    return bins,cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 in 1.21 mins.\n",
      "----------------------------------------------\n",
      "40 in 1.55 mins.\n",
      "----------------------------------------------\n",
      "41 in 1.97 mins.\n",
      "----------------------------------------------\n",
      "42 in 2.16 mins.\n",
      "----------------------------------------------\n",
      "43 in 2.71 mins.\n",
      "----------------------------------------------\n",
      "44 in 2.92 mins.\n",
      "----------------------------------------------\n",
      "45 in 3.06 mins.\n",
      "----------------------------------------------\n",
      "46 in 3.32 mins.\n",
      "----------------------------------------------\n",
      "47 in 3.68 mins.\n",
      "----------------------------------------------\n",
      "48 in 4.29 mins.\n",
      "----------------------------------------------\n",
      "49 in 4.4 mins.\n",
      "----------------------------------------------\n",
      "50 in 4.82 mins.\n",
      "----------------------------------------------\n",
      "51 in 4.41 mins.\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(39,52): \n",
    "    t0 = time.time()\n",
    "    t,cdf = rtcdf(i)\n",
    "    np.save('sim-'+str(i)+'-rt',np.array([t,cdf]))\n",
    "    del t,cdf\n",
    "    print(str(i) + ' in ' + str(round((time.time()-t0)/60,2)) + ' mins.')\n",
    "    print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.loglog(t,cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# investigate $\\text{var}\\{m\\}$ vs $\\kappa$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params_i = (15.56,22.07,4.52,3.56) # flow i \n",
    "params_a = (5.45, 6.59, 4.67,3.74) # flow a\n",
    "params_g = (7.74,8.42,4.95,4.34)\n",
    "params_l = (15.52,14.64,4.77,4.32)\n",
    "\n",
    "\n",
    "params=params_l\n",
    "\n",
    "nu,lam,sig,mu = params\n",
    "gam = nu/lam*(sig-mu) # this should make m0=mean(m).. this is important. \n",
    "\n",
    "kaps = np.geomspace(1e-6,5e-1,50)\n",
    "nmeans = []\n",
    "nvars = []\n",
    "mmeans=[]\n",
    "mvars = []\n",
    "i=0\n",
    "t0 = time.time()\n",
    "for kap in kaps:\n",
    "    n,m,t = sim(kap,params,tmax=24*3600)\n",
    "    if np.any(np.abs(kap*m)>1):\n",
    "        print('FAIL')\n",
    "    nmeans.append(trapz(n,t)/t[-1])\n",
    "    nvars.append(trapz(n**2,t)/t[-1]-(trapz(n,t)/t[-1])**2)\n",
    "    mvars.append(trapz(m**2,t)/t[-1])\n",
    "    mmeans.append(trapz(m,t)/t[-1])\n",
    "    i+=1\n",
    "    print('iteration {} in {} mins'.format(i,round((time.time()-t0)/60,2)))\n",
    "    t0 = time.time()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaps[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(kaps,mvars,'x',markersize=10,label='SIM')\n",
    "plt.loglog(kaps,1/kaps/4,color='black',label='MFT')\n",
    "#plt.xlim(1e-6,1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.loglog(kaps,nvars,'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.loglog(kaps,nmeans,'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keep the distinction straight: $\\langle n \\rangle = \\sum_m \\langle n | m\\rangle$\n",
    "# $\\langle n | m \\rangle $ decreases quasilinear with m\n",
    "# $ \\langle n^2 | m \\rangle $ decreases quasilinear with m \n",
    "# $ \\langle n \\rangle $ is roughly constant with $\\kappa$ provided $\\kappa < 10^{-2}$\n",
    "# $ \\langle n^2 \\rangle - \\langle n \\rangle^2$ is roughly constant under same conditions of small $\\kappa$\n",
    "# $\\langle m \\rangle = 0$ always\n",
    "# $\\langle m^2 \\rangle = \\frac{1}{4\\kappa}$ except for large $\\kappa \\approx 1$\n",
    "# you're left with two goals: get a MFT predicting $\\sigma_m^2 = \\frac{1}{4\\kappa}$ and $\\langle n^x | m \\rangle \\propto - m$\n",
    "# the key approximations are (1) m sees static n and (2) $\\kappa \\ll 1 $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.loglog(kaps,mvars,'x',markersize=10,label='SIM')\n",
    "plt.loglog(kaps,1/kaps/4,color='black',label='MFT')\n",
    "plt.title(r'MFT PREDICTS $\\sigma_m^2 = \\frac{1}{2\\kappa}$')\n",
    "plt.ylabel('VARIANCE IN M')\n",
    "plt.xlabel('COUPLING')\n",
    "plt.legend()\n",
    "#plt.xlim(1e-6,1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# study $\\text{var}\\{n\\}$ vs $\\kappa$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(kaps,nvars,'x')\n",
    "#plt.ylim(0,max(nvars))\n",
    "#plt.plot(kaps,1/kaps+min(nvars),color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# investigate $\\langle n | m \\rangle $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kap = 1e-3\n",
    "params=params_i\n",
    "n,m,t = sim(kap,params,tmax=24*3600)\n",
    "dt = np.diff(t)/t[-1] # used to weight averages\n",
    "n = n[:-1]\n",
    "m = m[:-1]\n",
    "del t\n",
    "nu, lam, sig, mu = params # all but gamma are specified\n",
    "gam = nu/lam*(sig-mu) # computed by conservation of mass at z=0\n",
    "nbar = (nu+lam)/(sig+gam-mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvals = np.arange(-150,150)\n",
    "nmeans = [(n[m==mi]*dt[m==mi]).sum()/dt[m==mi].sum() for mi in mvals]\n",
    "#n2 = [(n[m==mi]**2*dt[m==mi]).sum()/dt[m==mi].sum() for mi in mvals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condmean(mvals):\n",
    "    dm = - kap*mvals\n",
    "    return (lam*(1+dm)+nu)/(sig*(1-dm)+gam-mu*(1+dm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mvals,nmeans,'x')\n",
    "plt.axvline(0,color='black')\n",
    "plt.axhline(nbar,color='black')\n",
    "\n",
    "#plt.plot(mvals,nbar - kap*mvals*nbar**2)\n",
    "#plt.xlim(-3*m.std(),3*m.std())\n",
    "#plt.ylim(-3*n.std(),3*n.std())\n",
    "plt.plot(mvals,condmean(mvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.abs(kap*m)>0).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok conclusions on the mean suppression effect: It scales like kappa in some way I don't quite understand -- when kappa is relatively small the mean suppression is minimal, which means a proper mean field treatment should be totally good to go ... \n",
    "\n",
    "but at larger values of kappa there is a very strong variation of the mean with bed elevation. the mean flux is suppressed when the elevation is higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pure poisson only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params= (1.0,15.0,3.4,0.0)\n",
    "\n",
    "nu,lam,sig,mu = params\n",
    "gam = nu/lam*(sig-mu) # this should make m0=mean(m).. this is important. \n",
    "\n",
    "kaps = np.geomspace(1e-6,5e-2,30)\n",
    "nmeans = []\n",
    "nvars = []\n",
    "mmeans=[]\n",
    "mvars = []\n",
    "i=0\n",
    "t0 = time.time()\n",
    "for kap in kaps:\n",
    "    n,m,t = sim(kap,params,tmax=5*24*3600)\n",
    "    if np.any(np.abs(kap*m)>1):\n",
    "        print('FAIL')\n",
    "    nmeans.append(trapz(n,t)/t[-1])\n",
    "    nvars.append(trapz(n**2,t)/t[-1]-(trapz(n,t)/t[-1])**2)\n",
    "    mvars.append(trapz(m**2,t)/t[-1])\n",
    "    mmeans.append(trapz(m,t)/t[-1])\n",
    "    i+=1\n",
    "    print('iteration {} in {} mins'.format(i,round((time.time()-t0)/60,2)))\n",
    "    t0 = time.time()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(kaps,mvars,'x',markersize=10,label='SIM')\n",
    "plt.loglog(kaps,1/kaps/2,color='black',label='MFT')\n",
    "#plt.xlim(1e-6,1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[((m[:-1]==mv)*np.diff(t))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params= (2.0,24.0,4.4,3.5)\n",
    "nu,lam,sig,mu = params\n",
    "gam = nu/lam*(sig-mu) # this should make m0=mean(m).. this is important.\n",
    "kap = 1e-3\n",
    "n,m,t = sim(kap,params,tmax=5*24*3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(m[:-1]*dt).sum()/t[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvals = np.arange(-150,150,5)\n",
    "i = np.digitize(m,mvals)[:-1]-1\n",
    "dt = np.diff(t)\n",
    "means = [(n[:-1][ii==i]*dt[ii==i]).sum()/(dt[ii==i]).sum() for ii in np.unique(i)]\n",
    "mvals = mvals[np.unique(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
